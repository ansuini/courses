{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../../data/dl1/obj_neural_code/\"\n",
    "#path = \"../../data/obj_neural_code/sample/\"\n",
    "modelpath = \"../../models/dl1/vgg16_ft_obj_neural_code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1120 images belonging to 40 classes.\n",
      "Found 160 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1120/1120 [==============================] - 34s - loss: 3.6350 - acc: 0.2170 - val_loss: 1.0655 - val_acc: 0.6250\n",
      "Epoch 2/10\n",
      "1120/1120 [==============================] - 32s - loss: 1.2857 - acc: 0.6205 - val_loss: 0.5649 - val_acc: 0.8375\n",
      "Epoch 3/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.8894 - acc: 0.7330 - val_loss: 0.5480 - val_acc: 0.8313\n",
      "Epoch 4/10\n",
      "1120/1120 [==============================] - 33s - loss: 0.6548 - acc: 0.7821 - val_loss: 0.4600 - val_acc: 0.8375\n",
      "Epoch 5/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.5927 - acc: 0.8152 - val_loss: 0.3575 - val_acc: 0.8562\n",
      "Epoch 6/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.4972 - acc: 0.8429 - val_loss: 0.3354 - val_acc: 0.8688\n",
      "Epoch 7/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.4264 - acc: 0.8670 - val_loss: 0.3176 - val_acc: 0.9062\n",
      "Epoch 8/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.3754 - acc: 0.8786 - val_loss: 0.2400 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1120/1120 [==============================] - 33s - loss: 0.3665 - acc: 0.8795 - val_loss: 0.3008 - val_acc: 0.9062\n",
      "Epoch 10/10\n",
      "1120/1120 [==============================] - 32s - loss: 0.3068 - acc: 0.8982 - val_loss: 0.2834 - val_acc: 0.9125\n"
     ]
    }
   ],
   "source": [
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary\n",
    "base = vgg.model\n",
    "model_json = base.to_json()\n",
    "with open(modelpath + \"base.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "base.save_weights(modelpath+\"base.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_1\n",
      "maxpooling2d_1\n",
      "maxpooling2d_2\n",
      "maxpooling2d_3\n",
      "maxpooling2d_4\n",
      "maxpooling2d_5\n",
      "dense_1\n",
      "dense_2\n",
      "dense_4\n"
     ]
    }
   ],
   "source": [
    "idx = [0,5,10,17,24,31,33,35,37]\n",
    "layers  = []\n",
    "for i in range(len(idx)):\n",
    "    print(base.layers[idx[i]].name)\n",
    "    layers.append( base.layers[idx[i]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to disk\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for layer in layers:\n",
    "    #print base_model.get_layer(layer.name)\n",
    "    models.append( Model(input=base.input,\n",
    "                         output=base.get_layer(layer.name).output) )\n",
    "    \n",
    "for model in models:\n",
    "    NAME = model.layers[-1].name    \n",
    "    model_json = model.to_json()    \n",
    "    with open(modelpath + NAME + '.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(modelpath + NAME + '.h5')\n",
    "print(\"Saved models to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filelist with 1120 images\n"
     ]
    }
   ],
   "source": [
    "filelist = []\n",
    "range(1,40 + 1)\n",
    "for cat in range(1,40+1):\n",
    "    for f in os.listdir(path + 'train/' + str(cat)):\n",
    "        if f.endswith('.png'):\n",
    "            filename = path + 'train/' + str(cat) + '/' + f\n",
    "            filelist.append(filename)                \n",
    "print('Filelist with ' + str(len(filelist)) + ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "newpath = \"../../data/dl1/obj_neural_code/all_flat/\"\n",
    "batch_size = 60\n",
    "batches = vgg.get_batches(newpath, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = models[5].layers[-1].name  \n",
    "NAME\n",
    "\n",
    "nbatches = int(1440/batch_size)\n",
    "nbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.53175282478\n",
      "1.50188279152\n",
      "1.46206498146\n",
      "1.48755502701\n",
      "1.4870531559\n",
      "1.48069310188\n",
      "1.48744010925\n",
      "1.49954295158\n",
      "1.48403978348\n",
      "1.50717401505\n",
      "1.50781297684\n",
      "1.48199987411\n",
      "1.49620914459\n",
      "1.50108718872\n",
      "1.50102806091\n",
      "1.48641014099\n",
      "1.49899291992\n",
      "1.52116799355\n",
      "1.5209209919\n",
      "1.50491905212\n",
      "1.48009395599\n",
      "1.51470303535\n",
      "1.5037779808\n",
      "1.48276209831\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "R = []\n",
    "for n in range(nbatches):\n",
    "    imgs,_ = batches.next()\n",
    "    ti = time()\n",
    "    R.append( models[5].predict(imgs) )\n",
    "    te = time() - ti\n",
    "    print(te) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.asarray(R, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2.shape = [1440,512,7,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 512, 7, 7)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
