{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "datapath = \"../../data/dl1/obj_neural_code/\"\n",
    "flatdatapath = \"../../data/dl1/obj_neural_code/all_flat/\"\n",
    "repath   = \"../../data/dl1/obj_neural_code/rep/finetune/\"\n",
    "N = 1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.spatial.distance\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "idx = [0,5,10,17,24,31,33,35,37]\n",
    "# lambda_1\n",
    "# maxpooling2d_1\n",
    "# maxpooling2d_2\n",
    "# maxpooling2d_3\n",
    "# maxpooling2d_4\n",
    "# maxpooling2d_5\n",
    "# dense_1\n",
    "# dense_2\n",
    "# dense_3\n",
    "\n",
    "def get_models(idx,base):\n",
    "    layers  = []\n",
    "    for i in range(len(idx)):\n",
    "        print(base.layers[idx[i]].name)\n",
    "        layers.append( base.layers[idx[i]] )\n",
    "\n",
    "    models = []\n",
    "    outshapes = []\n",
    "    for layer in layers:\n",
    "        models.append( Model(input=base.input,\n",
    "                             output=base.get_layer(layer.name).output) )\n",
    "        outshapes.append(list( layer.output_shape ))\n",
    "        \n",
    "        \n",
    "    print('Done.')\n",
    "    return layers,models,outshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1120 images belonging to 40 classes.\n",
      "Found 160 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "nbatches = int(N/batch_size)\n",
    "batches = vgg.get_batches(datapath+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(datapath+'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1120/1120 [==============================] - 31s - loss: 3.8764 - acc: 0.1929 - val_loss: 1.1506 - val_acc: 0.6250\n",
      "Epoch 2/10\n",
      "1120/1120 [==============================] - 31s - loss: 1.3285 - acc: 0.6071 - val_loss: 0.6097 - val_acc: 0.7937\n",
      "Epoch 3/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.9261 - acc: 0.7170 - val_loss: 0.5714 - val_acc: 0.7937\n",
      "Epoch 4/10\n",
      "1120/1120 [==============================] - 30s - loss: 0.7639 - acc: 0.7696 - val_loss: 0.4275 - val_acc: 0.8563\n",
      "Epoch 5/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.5970 - acc: 0.8098 - val_loss: 0.3872 - val_acc: 0.9125\n",
      "Epoch 6/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.4678 - acc: 0.8438 - val_loss: 0.3431 - val_acc: 0.8937\n",
      "Epoch 7/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.4001 - acc: 0.8705 - val_loss: 0.4243 - val_acc: 0.8375\n",
      "Epoch 8/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.3661 - acc: 0.8884 - val_loss: 0.3078 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1120/1120 [==============================] - 31s - loss: 0.3920 - acc: 0.8786 - val_loss: 0.2796 - val_acc: 0.8875\n",
      "Epoch 10/10\n",
      "1120/1120 [==============================] - 30s - loss: 0.3140 - acc: 0.8884 - val_loss: 0.2795 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "vgg.finetune(batches)\n",
    "vgg.fit(batches, val_batches, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_1\n",
      "maxpooling2d_1\n",
      "maxpooling2d_2\n",
      "maxpooling2d_3\n",
      "maxpooling2d_4\n",
      "maxpooling2d_5\n",
      "dense_1\n",
      "dense_2\n",
      "dense_4\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "base = vgg.model\n",
    "layers,models,outshapes = get_models(idx,base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1440, 3, 224, 224]\n",
      "[1440, 64, 112, 112]\n",
      "[1440, 128, 56, 56]\n",
      "[1440, 256, 28, 28]\n",
      "[1440, 512, 14, 14]\n",
      "[1440, 512, 7, 7]\n",
      "[1440, 4096]\n",
      "[1440, 4096]\n",
      "[1440, 40]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outshapes)):\n",
    "    outshapes[i][0] = N\n",
    "    print(outshapes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model : lambda_1\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 3, 224, 224)\n",
      "228.873123169\n",
      "Processing model : maxpooling2d_1\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 64, 112, 112)\n",
      "1273.38632202\n",
      "Processing model : maxpooling2d_2\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 128, 56, 56)\n",
      "675.266762018\n",
      "Processing model : maxpooling2d_3\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 256, 28, 28)\n",
      "358.082916975\n",
      "Processing model : maxpooling2d_4\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 512, 14, 14)\n",
      "207.632259846\n",
      "Processing model : maxpooling2d_5\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 512, 7, 7)\n",
      "90.8472390175\n",
      "Processing model : dense_1\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 4096)\n",
      "58.68516922\n",
      "Processing model : dense_2\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 4096)\n",
      "59.9352638721\n",
      "Processing model : dense_4\n",
      "Found 1440 images belonging to 1 classes.\n",
      "(1440, 40)\n",
      "54.7917461395\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "D = []\n",
    "D_sq = []\n",
    "for layer,model in zip(layers,models):\n",
    "    print('Processing model : ' + layer.name)\n",
    "    R = []\n",
    "    batches = vgg.get_batches(flatdatapath, batch_size=batch_size, shuffle=False)\n",
    "    ti = time()\n",
    "    for n in range(nbatches):\n",
    "        imgs,_ = batches.next()       \n",
    "        R.append(model.predict(imgs))\n",
    "    R = np.asarray(R, dtype=float) \n",
    "    outshape = list(layer.output_shape)\n",
    "    outshape[0] = N\n",
    "    R.shape = tuple(outshape)\n",
    "    print(R.shape)\n",
    "    np.save(repath +  layer.name, R)\n",
    "        \n",
    "    # compute distances\n",
    "    R.shape = R.shape[0],-1\n",
    "    d = scipy.spatial.distance.pdist(R, 'euclidean')\n",
    "    d_sq = scipy.spatial.distance.squareform(d, force='no', checks=True)\n",
    "    D.append(d)\n",
    "    D_sq.append(d_sq)\n",
    "    te = time() - ti\n",
    "    print(te) \n",
    "    \n",
    "np.save(repath + 'D', D)\n",
    "np.save(repath + 'D_sq', D_sq)\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
